{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429e6d2-101b-45df-9958-85b10e8aa81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efae22-ca7c-44df-9bf2-8551c74d9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b304f-0f64-46d4-ae69-b03553c08034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from data import get_othello, plot_probs, plot_mentals\n",
    "from data.othello import permit, start_hands, OthelloBoardState, permit_reverse\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.model import GPT, GPTConfig, GPTforProbeIA\n",
    "from mingpt.utils import sample, intervene, print_board\n",
    "from mingpt.probe_model import BatteryProbeClassification, BatteryProbeClassificationTwoLayer\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', **{'size': 14.0})\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{lmodern}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8252c601-3340-4879-b979-df868947b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "championship = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be98be3c-f484-4a15-bbe9-a640ecb37bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_dim = 128\n",
    "how_many_history_step_to_use = 99\n",
    "exp = f\"state_tl{mid_dim}\"\n",
    "if championship:\n",
    "    exp += \"_championship\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c1fcf-a81e-4a0a-840a-50dce03258c3",
   "metadata": {},
   "source": [
    "## Load a game from intervention benchmark and select an intervention configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d694ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"./ckpts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de77e19-451a-4f3b-89fd-4efdba144882",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"intervention_benchmark.pkl\", \"rb\") as input_file:\n",
    "    dataset = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e08851-7508-4a56-993a-0f67be5ecb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id = 777\n",
    "wtd = {\n",
    "    \"intervention_position\": permit_reverse(dataset[case_id][\"pos_int\"]), \n",
    "    \"intervention_from\": dataset[case_id][\"ori_color\"], \n",
    "    \"intervention_to\": 2 - dataset[case_id][\"ori_color\"], \n",
    "}\n",
    "completion = dataset[case_id][\"history\"]\n",
    "print(wtd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89df37-9dea-4261-94e4-b602ec8cfffb",
   "metadata": {},
   "source": [
    "## Load nonlinear probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e85d97-4f7a-4c90-99b2-9b04cae1154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = {}\n",
    "layer_s = 4\n",
    "layer_e = 9\n",
    "for layer in range(layer_s, layer_e):\n",
    "    p = BatteryProbeClassificationTwoLayer(torch.cuda.current_device(), probe_class=3, num_task=128, mid_dim=mid_dim)\n",
    "    load_res = p.load_state_dict(torch.load(f\"{root_folder}/battery_othello/{exp}/layer{layer}/checkpoint.ckpt\"))\n",
    "    p.eval()\n",
    "    probes[layer] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96259d73-16a9-4ec2-94e2-1dbc294648b3",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0f8a5-b06b-454e-a1b2-a97d719f3d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# othello = get_othello(ood_perc=.2, data_root=\"data/othello_pgn\", wthor=False)\n",
    "# othello = get_othello(ood_perc=0., data_root=None, wthor=False, ood_num=1)\n",
    "othello = get_othello(data_root=\"data/othello_championship\", nfiles=3)\n",
    "train_dataset = CharDataset(othello)\n",
    "\n",
    "mconf = GPTConfig(121, 59, n_layer=8, n_head=8, n_embd=512)\n",
    "\n",
    "models = {}\n",
    "for layer in range(layer_s, layer_e):\n",
    "    model = GPTforProbeIA(mconf, probe_layer=layer)\n",
    "    # model = GPT(mconf)\n",
    "    load_res = model.load_state_dict(torch.load(f\"{root_folder}/gpt_synthetic.ckpt\" if not championship else \"./ckpts/gpt_championship.ckpt\"))\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        model = model.to(device)\n",
    "    _ = model.eval()\n",
    "    models[layer] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_board_1(seq):\n",
    "    return [x % 64 for x in seq]\n",
    "\n",
    "evaluation_dataset = [to_board_1(seq[:38]) for seq in train_dataset.data[:1000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc45bc-e369-44f4-bc5e-54bfec187825",
   "metadata": {},
   "source": [
    "### Check the partial game progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90954b-6e49-4b63-9dca-5851c748ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = OthelloBoardState()\n",
    "completion = evaluation_dataset[1]\n",
    "ab.update(completion, prt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd21ce5-6c66-419f-a4d0-2a5c12896862",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_game = torch.tensor([train_dataset.stoi[s] for s in completion], dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c7980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_mid_act = models[layer_s].forward_1st_stage(partial_game[None, :])  # [B, T, F=512]\n",
    "mid_act = whole_mid_act[0, -1]\n",
    "pre_intv_logits = probes[5](mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "probed_board = pre_intv_logits.argmax(axis=1)\n",
    "probed_states = (probed_board - 1).cpu().numpy()\n",
    "board = OthelloBoardState()\n",
    "board.state = probed_states[:64].reshape([8,8])\n",
    "board.__print__()\n",
    "board.state = probed_states[64:].reshape([8,8])\n",
    "board.__print__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8e035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "partial_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probing_board_score(game):\n",
    "    true_board = OthelloBoardState()\n",
    "    true_board.update(game)\n",
    "    \n",
    "    def score_for_indexes(true_board, game_indexes):\n",
    "        whole_mid_act = models[layer_s].forward_1st_stage(game_indexes[None, :])  # [B, T, F=512]\n",
    "        mid_act = whole_mid_act[0, -1]\n",
    "        pre_intv_logits = probes[5](mid_act[None, :])[0].squeeze(0)\n",
    "        probed_board = pre_intv_logits.argmax(axis=1)\n",
    "        probed_states = (probed_board - 1).cpu().numpy()\n",
    "    #     return true_board.state, probed_states[64:].reshape([8,8])\n",
    "        return (true_board.state.reshape(-1) == probed_states[64:]).sum() / 64\n",
    "    \n",
    "    game_indexes1 = torch.tensor([train_dataset.stoi[s] for s in game], dtype=torch.long).to(device)\n",
    "    game_indexes2 = torch.tensor([train_dataset.stoi[s+64] for s in game], dtype=torch.long).to(device)\n",
    "    return score_for_indexes(true_board, game_indexes2),score_for_indexes(true_board, game_indexes1)\n",
    "\n",
    "def mutual_representation_score(dataset):\n",
    "    acc, baseline = zip(\n",
    "        *[probing_board_score(x) for x in dataset]\n",
    "    )\n",
    "    return np.array(acc).mean(), np.array(baseline).mean()\n",
    "\n",
    "mutual_representation_score(evaluation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee87949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_matrix_90_deg(matrix):\n",
    "    # Step 1: Transpose the matrix\n",
    "    transposed_matrix = [[matrix[j][i] for j in range(len(matrix))] for i in range(len(matrix[0]))]\n",
    "    \n",
    "    # Step 2: Reverse each row\n",
    "    rotated_matrix = [row[::-1] for row in transposed_matrix]\n",
    "    \n",
    "    return np.array(rotated_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197278b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probing_board_score(game):\n",
    "    true_board = OthelloBoardState()\n",
    "    true_board.update(game)\n",
    "    \n",
    "    def score_for_indexes(true_board, game_indexes):\n",
    "        whole_mid_act = models[layer_s].forward_1st_stage(game_indexes[None, :])  # [B, T, F=512]\n",
    "        mid_act = whole_mid_act[0, -1]\n",
    "        pre_intv_logits = probes[5](mid_act[None, :])[0].squeeze(0)\n",
    "        probed_board = pre_intv_logits.argmax(axis=1)\n",
    "        probed_states = (probed_board - 1).cpu().numpy()\n",
    "        true_board_rotated_90deg = rotate_matrix_90_deg(true_board.state)\n",
    "        true_board_rotated_180deg = rotate_matrix_90_deg(true_board_rotated_90deg)\n",
    "        true_board_rotated_270deg = rotate_matrix_90_deg(true_board_rotated_180deg)\n",
    "        return (\n",
    "            (true_board.state.reshape(-1) == probed_states[64:]).sum() / 64,\n",
    "            (true_board_rotated_90deg.reshape(-1) == probed_states[64:]).sum() / 64,\n",
    "            (true_board_rotated_180deg.reshape(-1) == probed_states[64:]).sum() / 64,\n",
    "            (true_board_rotated_270deg.reshape(-1) == probed_states[64:]).sum() / 64,\n",
    "        )\n",
    "    \n",
    "    game_indexes1 = torch.tensor([train_dataset.stoi[s] for s in game], dtype=torch.long).to(device)\n",
    "    game_indexes2 = torch.tensor([train_dataset.stoi[s+64] for s in game], dtype=torch.long).to(device)\n",
    "    return score_for_indexes(true_board, game_indexes2)[0], *score_for_indexes(true_board, game_indexes1)\n",
    "\n",
    "def mutual_representation_score(dataset):\n",
    "    scores = zip(\n",
    "        *[probing_board_score(x) for x in dataset]\n",
    "    )\n",
    "    return [np.array(s).mean() for s in scores]\n",
    "\n",
    "mutual_representation_score(evaluation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e84e85-9c75-402c-9026-6dee99e4db46",
   "metadata": {},
   "source": [
    "### Check pre-intervention ground-truth legal next-steps and the predicted ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b0c20c-895c-4385-bb69-0ff45e39715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_intv_valids = [permit_reverse(_) for _ in ab.get_valid_moves()]\n",
    "pre_intv_valids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae5c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad9b4d1-5fd5-48db-add4-fa03305ad661",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_intv_pred, _ = model(partial_game[None, :])  # [B, T, F=512]\n",
    "# no history activations used here, that's why the prediction map is different to across layers\n",
    "pre_intv_pred = pre_intv_pred[0, -1, 1:]\n",
    "padding = torch.zeros(2).cuda()\n",
    "# pre_intv_pred = torch.softmax(pre_intv_pred, dim=0)  # keep logits\n",
    "pre_intv_pred = torch.cat(\n",
    "    [\n",
    "        pre_intv_pred[:27],\n",
    "        padding,\n",
    "        pre_intv_pred[27:33],\n",
    "        padding,\n",
    "        pre_intv_pred[33:27+60],\n",
    "        padding,\n",
    "        pre_intv_pred[27+60:33+60],\n",
    "        padding,\n",
    "        pre_intv_pred[33+60:]\n",
    "    ], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['classic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71efd0e-2614-41d5-9ac0-7d9bdf212c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
    "vv = 10\n",
    "gems = {\"pre\": pre_intv_pred.detach().cpu().numpy()[:64].reshape(8, 8)}\n",
    "sns.heatmap(pre_intv_pred.detach().cpu().numpy()[:64].reshape(8, 8), vmin=-vv, vmax=vv, \n",
    "            yticklabels=list(\"ABCDEFGH\"), xticklabels=list(range(1,9)), square=True, \n",
    "            annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a738d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
    "vv = 10\n",
    "gems = {\"pre\": pre_intv_pred.detach().cpu().numpy()[64:].reshape(8, 8)}\n",
    "sns.heatmap(pre_intv_pred.detach().cpu().numpy()[64:].reshape(8, 8), vmin=-vv, vmax=vv, \n",
    "            yticklabels=list(\"ABCDEFGH\"), xticklabels=list(range(1,9)), square=True, \n",
    "            annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e559c0-78b1-4114-af0f-521db6b7107d",
   "metadata": {},
   "source": [
    "## Intervene on all board positions and save prediction logits\n",
    "0 for white; 1 for blank; 2 for black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb64c34d-ec70-474b-a6c4-efe70aedcd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "htd = {\"lr\": 1e-3, \"steps\": 1000, \"reg_strg\": 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_probing = []\n",
    "for square in [permit_reverse(_) for _ in range(64)]:\n",
    "    p = probes[layer_s]\n",
    "    whole_mid_act = models[layer_s].forward_1st_stage(partial_game[None, :])  # [B, T, F=512]\n",
    "    mid_act = whole_mid_act[0, -1]\n",
    "    pre_intv_logits = p(mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "    break\n",
    "pre_intv_logits.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_mid_act = models[layer_s].forward_1st_stage(partial_game[None, :])  # [B, T, F=512]\n",
    "mid_act = whole_mid_act[0, -1]\n",
    "pre_intv_logits = probes[6](mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "probed_board = pre_intv_logits.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probed_board.reshape([8,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef294d-ad0b-4256-bd16-0ef533250e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for square in [permit_reverse(_) for _ in range(64)]:\n",
    "    wtd[\"intervention_position\"] = square\n",
    "    move = permit(wtd[\"intervention_position\"])\n",
    "    r, c = move // 8, move % 8\n",
    "    wtd[\"intervention_from\"] = ab.state[r, c] + 1\n",
    "    wtd[\"intervention_to\"] = 2 - wtd[\"intervention_from\"]\n",
    "    wtd_list = [wtd]\n",
    "    \n",
    "    p = probes[layer_s]\n",
    "    whole_mid_act = models[layer_s].forward_1st_stage(partial_game[None, :])  # [B, T, F=512]\n",
    "\n",
    "    # intervene at the earlest interested layer \n",
    "    mid_act = whole_mid_act[0, -1]\n",
    "    pre_intv_logits = p(mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "    labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "    new_mid_act = mid_act.clone()\n",
    "    for wtd in wtd_list:\n",
    "        new_mid_act = intervene(p, new_mid_act, labels_pre_intv, wtd, htd, plot=True)\n",
    "        pre_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "        labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "\n",
    "    # swap in \n",
    "    whole_mid_act[0, -1] = new_mid_act\n",
    "\n",
    "    for i, layer in enumerate(range(layer_s, layer_e - 1)):  # 4, 5, 6, 7, indices of the layers to be passed\n",
    "        p = probes[layer+1]\n",
    "        whole_mid_act = models[layer_s].forward_2nd_stage(whole_mid_act, layer, layer+1)[0]  # [1, T, F=512]\n",
    "\n",
    "        # intervene the output of the features freshly out\n",
    "        mid_act = whole_mid_act[0, -1]\n",
    "        pre_intv_logits = p(mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "        labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "        new_mid_act = mid_act.clone()\n",
    "        for wtd in wtd_list:\n",
    "            new_mid_act = intervene(p, new_mid_act, labels_pre_intv, wtd, htd, plot=True)\n",
    "            pre_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "            labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "        # swap in \n",
    "        whole_mid_act[0, -1] = new_mid_act\n",
    "\n",
    "    tb_resumed = whole_mid_act\n",
    "    post_intv_pred, _ = models[layer_s].predict(tb_resumed)\n",
    "    post_intv_pred = post_intv_pred[0, -1, 1:]\n",
    "    # post_intv_pred = torch.softmax(post_intv_pred, dim=0)\n",
    "    post_intv_pred = torch.cat([post_intv_pred[:27], padding, post_intv_pred[27:33], padding, post_intv_pred[33:]], dim=0)\n",
    "    if 0:\n",
    "        gems[square] = torch.softmax(post_intv_pred, dim=0).detach().cpu().numpy().reshape(8, 8)\n",
    "    else:   \n",
    "        gems[square] = post_intv_pred.detach().cpu().numpy().reshape(8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058a6362-505d-481a-96e5-1c52afdb5e1b",
   "metadata": {},
   "source": [
    "## Plot Attribution via Intervention heatmaps for all legal next-moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48fb467-8901-4362-9d57-7ffb24a3cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbu = pre_intv_valids\n",
    "total = len(tbu)\n",
    "rows = math.ceil(total / 4)\n",
    "\n",
    "fig, axs = plt.subplots(rows, 4, figsize=(30, rows * 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "axs = axs.flat\n",
    "\n",
    "for i, tobe_tcaved in enumerate(tbu):\n",
    "    pred = permit(tobe_tcaved)  # 0-63\n",
    "    r_pred, c_pred = pred // 8, pred % 8\n",
    "\n",
    "    tbp = np.zeros((8, 8), )\n",
    "    pre = gems[\"pre\"]\n",
    "    for k, w in gems.items():\n",
    "        if k == \"pre\":\n",
    "            continue\n",
    "        move = permit(k)  # 0-63\n",
    "        r, c = move // 8, move % 8\n",
    "        tbp[r, c] = - w[r_pred, c_pred] + pre[r_pred, c_pred]\n",
    "    ab.plot_hm(axs[i], tbp.flatten(), permit(tobe_tcaved), logit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0187a9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "othello"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
